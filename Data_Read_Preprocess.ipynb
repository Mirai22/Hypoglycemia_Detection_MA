{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load glucose from xml data, attributes are value and the time, round and resample the time series to 5 minutes\n",
    "# rounding can cause dupllicates as why only the first value is kept and\n",
    "# resampling is needed to obtain a full sequence and identify gaps\n",
    "# code for reading the xml files is influenced/copied by https://github.com/r-cui/GluPred/blob/master/preprocess/loader.py\n",
    "\n",
    "def get_glc(root):\n",
    "    glucose = []\n",
    "    glucose_ts = []\n",
    "    for type_tag in root.findall('glucose_level/event'):\n",
    "        value = type_tag.get('value')\n",
    "        ts = type_tag.get('ts')\n",
    "        ts = datetime.datetime.strptime(ts, \"%d-%m-%Y %H:%M:%S\")\n",
    "        glucose.append(int(value))\n",
    "        glucose_ts.append(ts)\n",
    "        \n",
    "    glc_frame = [glucose_ts, glucose]\n",
    "    glc_frame = np.array(glc_frame)\n",
    "    df_glc = pd.DataFrame(glc_frame.T, columns=['ts', 'glucose'])\n",
    "    df_glc[\"ts\"] = df_glc[\"ts\"].dt.round('5min')\n",
    "    df_glc[\"ts\"] = df_glc[\"ts\"].drop_duplicates()\n",
    "\n",
    "    df_glc = df_glc.set_index('ts')\n",
    "    df_glc = df_glc.resample(\"5min\").asfreq()\n",
    "    df_glc = df_glc.reset_index()\n",
    "    #df_glc = df_glc.fillna(-1)\n",
    "\n",
    "    return df_glc\n",
    "\n",
    "\n",
    "\n",
    "# load insulin data consisting of basal, temp_basal, and bolus,\n",
    "# basal and temp_basal need to be comniend and the original basal value is replaced wtih temp_basal\n",
    "# furthermore., basal is resampled to 5 minutes and the missing values are filled with the prior values\n",
    "# as basal is applied continously, it only changes when a new basal rate is set\n",
    "\n",
    "def get_basal(root):\n",
    "    basal = []\n",
    "    basal_ts = []\n",
    "\n",
    "    for type_tag in root.findall('basal/event'):\n",
    "        value = type_tag.get('value')\n",
    "        ts = type_tag.get('ts')\n",
    "        ts = datetime.datetime.strptime(ts, \"%d-%m-%Y %H:%M:%S\")\n",
    "        basal.append(float(value))\n",
    "        basal_ts.append(ts)\n",
    "\n",
    "    basal_frame = [basal_ts, basal]\n",
    "    basal_frame = np.array(basal_frame)\n",
    "    df_basal = pd.DataFrame(basal_frame.T, columns=['ts', 'basal'])\n",
    "\n",
    "    df_basal[\"ts\"] = pd.to_datetime(df_basal[\"ts\"])\n",
    "\n",
    "    df_basal = df_basal.set_index('ts')\n",
    "    df_basal = df_basal.resample(\"5min\").ffill()\n",
    "    df_basal = df_basal.reset_index()\n",
    "\n",
    "\n",
    "\n",
    "    return df_basal\n",
    "\n",
    "# temp_basal is a temporary dosage replacing the original basal rate, with a value of 0 the basal rate is suspended\n",
    "\n",
    "def get_temp_basal(root):\n",
    "    temp_basal = []\n",
    "    temp_basal_ts = []\n",
    "    temp_basal_dur = []\n",
    "\n",
    "    for type_tag in root.findall('temp_basal/event'):\n",
    "        value = type_tag.get('value')\n",
    "        ts = type_tag.get('ts_begin')\n",
    "        ts_end = type_tag.get('ts_end')\n",
    "        ts = datetime.datetime.strptime(ts, \"%d-%m-%Y %H:%M:%S\")\n",
    "        ts_end = datetime.datetime.strptime(ts_end, \"%d-%m-%Y %H:%M:%S\")\n",
    "        temp_basal_dur.append(ts_end)\n",
    "        temp_basal.append(float(value))\n",
    "        temp_basal_ts.append(ts)\n",
    "\n",
    "    temp_basal_frame = [temp_basal_ts, temp_basal, temp_basal_dur]\n",
    "    temp_basal_frame = np.array(temp_basal_frame)\n",
    "    df_temp_basal = pd.DataFrame(temp_basal_frame.T, columns=['ts', 'temp_basal', 'basal_end'])\n",
    "\n",
    "    df_temp_basal[\"ts\"] = pd.to_datetime(df_temp_basal[\"ts\"] )\n",
    "    df_temp_basal[\"basal_end\"] = pd.to_datetime(df_temp_basal[\"basal_end\"])\n",
    "\n",
    "    df_temp_basal[\"ts\"] = df_temp_basal[\"ts\"].dt.round('5min')\n",
    "    df_temp_basal[\"basal_end\"] = df_temp_basal[\"basal_end\"].dt.round('5min')\n",
    "    return df_temp_basal\n",
    "\n",
    "# This function aims to replace temp basal with basal value, by identifying the start and end time of\n",
    "# temporal basal infusion\n",
    "\n",
    "def combine_basal_temp_basal(df_b, df_temp_b):\n",
    "\n",
    "    \n",
    "    combined_df = pd.merge(df_b, df_temp_b, on='ts', how='left')\n",
    "    combined_df[\"temp_basal\"] = combined_df[\"temp_basal\"].fillna(-1)\n",
    "\n",
    "    for i in range (0, len(combined_df)):\n",
    "        if((combined_df[\"temp_basal\"][i]  != -1)):\n",
    "            start_time = combined_df[\"ts\"][i]\n",
    "            end_time = combined_df[\"basal_end\"][i]\n",
    "            combined_df.loc[(combined_df[\"ts\"] >= start_time) & (combined_df[\"ts\"] <= end_time), \"basal\"] = combined_df[\"temp_basal\"][i]  \n",
    "\n",
    "    combined_df = combined_df.drop(\"basal_end\", axis=1) \n",
    "    combined_df = combined_df.drop(\"temp_basal\", axis=1) \n",
    "    return combined_df\n",
    "\n",
    "\n",
    "# bolus insulin is another insulin which is not infused continously, here the start and endtime need to be identified to set the\n",
    "# correct bolus for each infusion duration\n",
    "\n",
    "\n",
    "def get_bolus(root): \n",
    "    bolus = []\n",
    "    bolus_ts = []\n",
    "    bolus_end = []\n",
    "\n",
    "    for type_tag in root.findall('bolus/event'):\n",
    "        value = type_tag.get('dose')\n",
    "        ts = type_tag.get('ts_begin')\n",
    "        ts = datetime.datetime.strptime(ts, \"%d-%m-%Y %H:%M:%S\")\n",
    "        ts_end = type_tag.get('ts_end')\n",
    "        ts_end = datetime.datetime.strptime(ts_end, \"%d-%m-%Y %H:%M:%S\")\n",
    "        bolus_ts.append(ts)\n",
    "        bolus_end.append(ts_end)\n",
    "        bolus.append(float(value))\n",
    "\n",
    "    bolus_frame = [bolus_ts, bolus, bolus_end]\n",
    "    bolus_frame = np.array(bolus_frame)\n",
    "    df_bolus =pd.DataFrame(bolus_frame.T, columns=['ts', 'bolus', 'bolus_end'])\n",
    "    \n",
    "    df_bolus['ts'] = df_bolus['ts'].dt.round('5min')\n",
    "    df_bolus[\"ts\"] = df_bolus[\"ts\"].drop_duplicates()\n",
    "\n",
    "    df_bolus['bolus_end'] = df_bolus['bolus_end'].dt.round('5min')\n",
    "    df_bolus['bolus_end'] = df_bolus['bolus_end'].drop_duplicates()\n",
    "\n",
    "    return df_bolus\n",
    "\n",
    "\n",
    "# load exercise:\n",
    "# The problem with the exercise data is that both patient cohorts use different wearables and parameters, hence to have \n",
    "# uniform data, the magnitude of acceleration from dataset 2020 is converted to step count while the step count of\n",
    "# the 2018 dataset is kept\n",
    "\n",
    "def get_step(root):\n",
    "    steps = []\n",
    "    steps_ts = []\n",
    "    for type_tag in root.findall('basis_steps/event'):\n",
    "        value = type_tag.get('value')\n",
    "        ts = type_tag.get('ts')\n",
    "        ts = datetime.datetime.strptime(ts, \"%d-%m-%Y %H:%M:%S\")\n",
    "        steps.append(int(value))\n",
    "        steps_ts.append(ts)\n",
    "\n",
    "    steps_frame = [steps_ts, steps]\n",
    "    steps_frame = np.array(steps_frame)\n",
    "    df_steps = pd.DataFrame(steps_frame.T, columns=['ts', 'steps'])\n",
    "\n",
    "    df_steps['ts'] = df_steps['ts'].dt.round('5min')\n",
    "    df_steps['ts'] = df_steps['ts'].drop_duplicates()\n",
    "\n",
    "    # read sleep data recorded by the wearable \n",
    "    # i think if this is recorded then the activity as well\n",
    "    df_sleep_basis = get_sleep_basis(root)\n",
    "    combined_df_1 = combine_step_sleep(df_steps, df_sleep_basis)\n",
    "    # read self reported sleep data and replace values\n",
    "    df_sleep = get_sleep(root)\n",
    "    combined_df = combine_step_sleep(combined_df_1, df_sleep)\n",
    "    # convert the step count to magnitude of acceleration\n",
    "    df_macc = convert_step_to_MOA(combined_df)\n",
    "\n",
    "    return df_macc\n",
    "\n",
    "\n",
    "## the step count could have datagaps as why the sleep time information is extracted to include 0 activity while sleeping\n",
    "\n",
    "def get_sleep_basis(root):\n",
    "    sleep_start = []\n",
    "    sleep_end = []\n",
    "    for type_tag in root.findall('basis_sleep/event'):\n",
    "        start = type_tag.get('tbegin')\n",
    "        end = type_tag.get('tend')\n",
    "        start = datetime.datetime.strptime(start, \"%d-%m-%Y %H:%M:%S\")\n",
    "        end = datetime.datetime.strptime(end, \"%d-%m-%Y %H:%M:%S\")\n",
    "        sleep_start.append(start)\n",
    "        sleep_end.append(end)\n",
    "        \n",
    "    sleep_frame = [sleep_start, sleep_end]\n",
    "    sleep_frame = np.array(sleep_frame)\n",
    "    df_sleep = pd.DataFrame(sleep_frame.T, columns=['ts', 'sleep_end'])\n",
    "    df_sleep['ts'] = df_sleep['ts'].dt.round('5min')\n",
    "    df_sleep['sleep_end'] = df_sleep['sleep_end'].dt.round('5min')\n",
    "\n",
    "    return df_sleep\n",
    "\n",
    "# get sleep information to fill possible gaps in exercise data with 0 for no exercise\n",
    "# during sleep\n",
    "\n",
    "def get_sleep(root):\n",
    "    sleep_start = []\n",
    "    sleep_end = []\n",
    "    for type_tag in root.findall('sleep/event'):\n",
    "        start = type_tag.get('ts_end')\n",
    "        end = type_tag.get('ts_begin')\n",
    "        start = datetime.datetime.strptime(start, \"%d-%m-%Y %H:%M:%S\")\n",
    "        end = datetime.datetime.strptime(end, \"%d-%m-%Y %H:%M:%S\")\n",
    "        sleep_start.append(start)\n",
    "        sleep_end.append(end)\n",
    "        \n",
    "    sleep_frame = [sleep_start, sleep_end]\n",
    "    sleep_frame = np.array(sleep_frame)\n",
    "    df_sleep = pd.DataFrame(sleep_frame.T, columns=['ts', 'sleep_end'])\n",
    "    df_sleep['ts'] = df_sleep['ts'].dt.round('5min')\n",
    "    df_sleep['sleep_end'] = df_sleep['sleep_end'].dt.round('5min')\n",
    "\n",
    "    return df_sleep\n",
    "\n",
    "\n",
    "# set step count to 0 if the patient is sleeping\n",
    "\n",
    "def combine_step_sleep(df_step, df_sleep):\n",
    "\n",
    "    \n",
    "    combined_df = pd.merge(df_step, df_sleep, on='ts', how='left')\n",
    "    combined_df[\"steps\"] = combined_df[\"steps\"].fillna(-1)\n",
    "\n",
    "    for i in range (0, len(combined_df)):\n",
    "        if((combined_df[\"steps\"][i]  != -1)):\n",
    "            start_time = combined_df[\"ts\"][i]\n",
    "            end_time = combined_df[\"sleep_end\"][i]\n",
    "            combined_df.loc[(combined_df[\"ts\"] >= start_time) & (combined_df[\"sleep_end\"] <= end_time), \"steps\"] = 0\n",
    "\n",
    "    combined_df = combined_df.drop(\"sleep_end\", axis=1) \n",
    "\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "'''\n",
    "formulas are taken from:\n",
    "https://www.omnicalculator.com/physics/velocity : velocity\n",
    "https://www.omnicalculator.com/physics/magnitude-of-acceleration : acceleration and magnitude of acceleration\n",
    "\n",
    "- The formula for the magnitude of acceleration is the absolute value of the acceleration with a formula of |a| = sqrt(pow(x))\n",
    "- x in this case is the acceleration computed by the change in velocity divided by the time interval\n",
    "- so for converting step count into the magnitude of acceleration, the first step is to compute the velocity from the distance divided by the needed time\n",
    "- velocity = distance/time\n",
    "- acc = change in velocity/ change in time\n",
    "- moacc = |a| = sqrt(pow(x)) -> the absolute value was not taken since the 2020 also indicate negative acceleration\n",
    "\n",
    "1. First, we will convert the step count to a distance of meters. Here, according to research the satndard equality is 1 step = 0.74 - 0.76 meters. We further will convert the time from minutes to seconds\n",
    "    - In this case, we will use: velocity = (step count * 0.75) / (60 * 5)\n",
    "2. Secondly, we will caluclate the acceleration from subtracting the considered velocity from the previous velocity (initial) and divide it again by (60 * 5)\n",
    "3. Third, we will calcuate the magnitude of acceleration from the given acceleration'''\n",
    "\n",
    "def convert_step_to_MOA(df_steps):\n",
    "    time_interval = 5  \n",
    "\n",
    "    df_steps['steps'] = df_steps['steps'].mul(0.75)\n",
    "    df_steps['velocity'] = df_steps['steps'].div(time_interval) \n",
    "    df_steps.loc[(df_steps[\"steps\"] == 0), \"velocity\"] = 0.0\n",
    "    df_steps['prior_velocity'] = df_steps['velocity'].shift(1, axis=0)\n",
    "    df_steps['difference'] = df_steps['velocity'] - df_steps['prior_velocity']\n",
    "    df_steps['acc'] = df_steps['difference'].div(time_interval) \n",
    "    df_steps['macc'] = df_steps['acc']#.abs()\n",
    "\n",
    "    df_steps.loc[(df_steps[\"velocity\"] == 0) & (df_steps[\"prior_velocity\"] == 0) , \"macc\"] = 0.0\n",
    "\n",
    "    df_macc = df_steps[['ts', 'macc']]\n",
    "\n",
    "    # scale the data to 0 and 1 to have similar scaled values as the 2020 MoA \n",
    "    df_min_max_scaled = df_macc.copy() \n",
    "    df_min_max_scaled ['macc'] = (df_min_max_scaled['macc'] - df_min_max_scaled['macc'].min()) / (df_min_max_scaled['macc'].max() - df_min_max_scaled['macc'].min())  \n",
    "    \n",
    "    return df_min_max_scaled\n",
    "\n",
    "\n",
    "\n",
    "# extract the acceleration data for the 2020 cohort\n",
    "\n",
    "def get_macc(root):\n",
    "\n",
    "    macc = []\n",
    "    macc_ts = []\n",
    "\n",
    "    for type_tag in root.findall('acceleration/event'):\n",
    "        value = type_tag.get('value')\n",
    "        ts = type_tag.get('ts')\n",
    "        ts = datetime.datetime.strptime(ts, \"%d-%m-%Y %H:%M:%S\")\n",
    "        macc.append(float(value))\n",
    "        macc_ts.append(ts)\n",
    "    macc_frame = [macc_ts, macc]\n",
    "    macc_frame = np.array(macc_frame)\n",
    "    df_macc = pd.DataFrame(macc_frame.T, columns=['ts', 'macc'])\n",
    "\n",
    "    # resample to 5 minutes and sum the magnitude of the single minutes so that every 5 minutes the MoA summed over 5 minutes is presented\n",
    "    df_macc = df_macc.set_index('ts')\n",
    "    df_macc = df_macc.resample(\"5min\").sum() # asfreq(), sum() or average() since here we are upsampling, and I think the acceleartion is the accelaertion per minute \n",
    "    df_macc = df_macc.reset_index()\n",
    "    df_macc = df_macc.replace(0.0, np.nan)\n",
    "\n",
    "    # scale the data to 0 and 1 to have similar scaled values as the converted MoA from step size\n",
    "    df_min_max_scaled = df_macc.copy() \n",
    "    df_min_max_scaled ['macc'] = (df_min_max_scaled['macc'] - df_min_max_scaled['macc'].min()) / (df_min_max_scaled['macc'].max() - df_min_max_scaled['macc'].min())  \n",
    "    \n",
    "    return df_min_max_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for generating the classes, takes the start and end of the interval which is occuring before the hypoglycemic event\n",
    "# only instances which were not assigned to another class are considered\n",
    "def Class_generation(df, start, end, class_number, list_hypo):\n",
    "    \n",
    "\n",
    "    for i in list_hypo:\n",
    "        current_time = pd.to_datetime(i)\n",
    "        start_time = current_time - datetime.timedelta(minutes = start)\n",
    "        end_time = current_time - datetime.timedelta(minutes = end)\n",
    "\n",
    "\n",
    "        df.loc[(df[\"ts\"] < start_time) & (df[\"ts\"] >= end_time) & (df[\"Class\"] == -1), \"Class\"] = class_number\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all data and combien columsn for one df epr patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # same for the extrapolated\\n    df_extra = df2.copy().reset_index()\\n    dataframes_extra = []\\n\\n    # identify the indexes of nan values to split the original data based on those gaps\\n    nan_mask_extra = df_extra[\\'glucose\\'].isnull()\\n    cumultative_sum_extra = nan_mask_extra.cumsum()\\n    # build groups of occuring values of the same type\\n    groups_extra = df_extra.groupby(cumultative_sum_extra)\\n\\n    # iterate through the groups and only add dataframes to the list which do not cantain nan values\\n    for _, group in groups_extra: \\n        if group[\\'glucose\\'].isnull().all(): \\n            continue\\n        group = group.dropna()\\n        dataframes_extra.append(group)\\n\\n\\n    for i in range (0, len(dataframes_extra)):\\n        file_name2 = \"GAPS_DATA/TEST/%s/%s_%i_%i_EXTRA.csv\" % (subject_ID,subject_ID, i, version)\\n        dataframes_extra[i].to_csv(file_name2)'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## identify gap and split dataframe\n",
    "# (with the help of chatpgt)\n",
    "def Remove_big_gaps(df, subject_ID, version):\n",
    "\n",
    "    df_inter = df.copy().reset_index()\n",
    "    dataframes_inter = []\n",
    "\n",
    "    # identify the indexes of nan values to split the original data based on those gaps\n",
    "    nan_mask_inter = df_inter['glucose'].isnull()\n",
    "    cumultative_sum_inter = nan_mask_inter.cumsum()\n",
    "    # build groups of occuring values of the same type\n",
    "    groups_inter = df_inter.groupby(cumultative_sum_inter)\n",
    "\n",
    "    # iterate through the groups and only add dataframes to the list which do not cantain nan values\n",
    "    for _, group in groups_inter: \n",
    "        if group['glucose'].isnull().all(): \n",
    "            continue\n",
    "        group = group.dropna()\n",
    "        dataframes_inter.append(group)\n",
    "\n",
    "    for i in range (0, len(dataframes_inter)):\n",
    "        file_name = \"GAPS_DATA/TRAIN/%s/%s_%i_%i_INTER.csv\" % (subject_ID,subject_ID, i, version)\n",
    "        dataframes_inter[i].to_csv(file_name)\n",
    "\n",
    "''' # same for the extrapolated\n",
    "    df_extra = df2.copy().reset_index()\n",
    "    dataframes_extra = []\n",
    "\n",
    "    # identify the indexes of nan values to split the original data based on those gaps\n",
    "    nan_mask_extra = df_extra['glucose'].isnull()\n",
    "    cumultative_sum_extra = nan_mask_extra.cumsum()\n",
    "    # build groups of occuring values of the same type\n",
    "    groups_extra = df_extra.groupby(cumultative_sum_extra)\n",
    "\n",
    "    # iterate through the groups and only add dataframes to the list which do not cantain nan values\n",
    "    for _, group in groups_extra: \n",
    "        if group['glucose'].isnull().all(): \n",
    "            continue\n",
    "        group = group.dropna()\n",
    "        dataframes_extra.append(group)\n",
    "\n",
    "\n",
    "    for i in range (0, len(dataframes_extra)):\n",
    "        file_name2 = \"GAPS_DATA/TEST/%s/%s_%i_%i_EXTRA.csv\" % (subject_ID,subject_ID, i, version)\n",
    "        dataframes_extra[i].to_csv(file_name2)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Count_Initial_Hypo(TRAINFILE, TESTFILE, s_ID):\n",
    "\n",
    "    count = 0\n",
    "    for i in range(0, len(TRAINFILE)):\n",
    "        root = ET.parse(TRAINFILE[i]).getroot()\n",
    "        root2 = ET.parse(TESTFILE[i]).getroot()\n",
    "\n",
    "        subject_ID = s_ID[count]\n",
    "        count = count +1\n",
    "        # read the single dataframes\n",
    "\n",
    "        glucose = []\n",
    "        glucose_ts = []\n",
    "        for type_tag in root.findall('glucose_level/event'):\n",
    "            value = type_tag.get('value')\n",
    "            ts = type_tag.get('ts')\n",
    "            ts = datetime.datetime.strptime(ts, \"%d-%m-%Y %H:%M:%S\")\n",
    "            glucose.append(int(value))\n",
    "            glucose_ts.append(ts)\n",
    "            \n",
    "        glc_frame = [glucose_ts, glucose]\n",
    "        glc_frame = np.array(glc_frame)\n",
    "        df_glc = pd.DataFrame(glc_frame.T, columns=['ts', 'glucose'])\n",
    "\n",
    "\n",
    "        glucose2 = []\n",
    "        glucose_ts2 = []\n",
    "        for type_tag in root2.findall('glucose_level/event'):\n",
    "            value2 = type_tag.get('value')\n",
    "            ts2 = type_tag.get('ts')\n",
    "            ts2 = datetime.datetime.strptime(ts2, \"%d-%m-%Y %H:%M:%S\")\n",
    "            glucose2.append(int(value2))\n",
    "            glucose_ts2.append(ts2)\n",
    "            \n",
    "        glc_frame2 = [glucose_ts2, glucose2]\n",
    "        glc_frame2 = np.array(glc_frame2)\n",
    "        df_glc2 = pd.DataFrame(glc_frame2.T, columns=['ts', 'glucose'])\n",
    "\n",
    "        df_glc3 = pd.concat([df_glc, df_glc2])\n",
    "\n",
    "        # read the single dataframes\n",
    "        df_glc3[\"Class\"] = 1\n",
    "        df_glc3.loc[df_glc3[\"glucose\"] <= 70, \"Class\"] = 0\n",
    "        print(subject_ID)\n",
    "        print(np.bincount(df_glc3['Class']))\n",
    "        print(len(df_glc3['Class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load the data, combine the single columns, fill in missing data and assing the subject ids\n",
    "# as input the file ordner which is either train or test, likewise the moduse, and finally the subjects id and version is given \n",
    "# which can be 2018 or 2020\n",
    "\n",
    "def load_data(TRAINFILE, TESTFILE, s_ID, version, modus):\n",
    "\n",
    "    count = 0\n",
    "    for i in range(0, len(TRAINFILE)):\n",
    "        root = ET.parse(TRAINFILE[i]).getroot()\n",
    "        root2 = ET.parse(TESTFILE[i]).getroot()\n",
    "\n",
    "        subject_ID = s_ID[count]\n",
    "        count = count +1\n",
    "        # read the single dataframes\n",
    "        \n",
    "\n",
    "        # read the single dataframes\n",
    "        df_glc = get_glc(root)\n",
    "        df_basal = get_basal(root)\n",
    "        df_bolus = get_bolus(root)\n",
    "        df_temp_basal = get_temp_basal(root)\n",
    "        # take the step count if the patient is from the 2018 cohort\n",
    "        # and convert the data to the magnitude of acceleration\n",
    "        # otherwise, take the magnitude of acceleration directly\n",
    "\n",
    "        if version == 2018:\n",
    "            df_macc = get_step(root)\n",
    "        else:\n",
    "            df_macc = get_macc(root)\n",
    "\n",
    "        # combine single dataframes and add the subject id\n",
    "        df_list = [df_glc, df_basal, df_bolus, df_macc] \n",
    "        combined_df = df_list[0]\n",
    "        for i in range(1,len(df_list)):\n",
    "            combined_df = pd.merge(combined_df, df_list[i], on='ts', how='left')\n",
    "\n",
    "\n",
    "\n",
    "        ## iterate over the testing data\n",
    "        df_glc2 = get_glc(root2)\n",
    "        df_basal2 = get_basal(root2)\n",
    "        df_bolus2 = get_bolus(root2)\n",
    "        df_temp_basal2 = get_temp_basal(root2)\n",
    "        # take the step count if the patient is from the 2018 cohort\n",
    "        # and convert the data to the magnitude of acceleration\n",
    "        # otherwise, take the magnitude of acceleration directly\n",
    "\n",
    "        if version == 2018:\n",
    "            df_macc2 = get_step(root2)\n",
    "        else:\n",
    "            df_macc2 = get_macc(root2)\n",
    "\n",
    "\n",
    "        # combine single dataframes and add the subject id\n",
    "        df_list2 = [df_glc2, df_basal2, df_bolus2, df_macc2] \n",
    "        combined_df_test = df_list2[0]\n",
    "        for i in range(1,len(df_list2)):\n",
    "            combined_df_test = pd.merge(combined_df_test, df_list2[i], on='ts', how='left')\n",
    "\n",
    "\n",
    "        combined_df = pd.concat([combined_df, combined_df_test])\n",
    "        combined_df[\"Subject_ID\"] = subject_ID\n",
    "        combined_df = combined_df.reset_index()\n",
    "        combined_df = combined_df.drop(columns='index')\n",
    "\n",
    "        # replace temporal basal with original basal for given time intervalls\n",
    "        combined_df = combine_basal_temp_basal(combined_df, df_temp_basal)\n",
    "        combined_df = combine_basal_temp_basal(combined_df, df_temp_basal2)\n",
    "\n",
    "        # integrate bolus over the time horizon on which it is applied by also deleting the row bolus_end\n",
    "        for i in range (0, len(combined_df)):\n",
    "            if((combined_df[\"bolus\"][i]  != np.NaN)):\n",
    "                start_time = combined_df[\"ts\"][i]\n",
    "                end_time = combined_df[\"bolus_end\"][i]\n",
    "                combined_df.loc[(combined_df[\"ts\"] >= start_time) & (combined_df[\"ts\"] <= end_time), \"bolus\"] = combined_df[\"bolus\"][i]  \n",
    "\n",
    "        combined_df = combined_df.drop(\"bolus_end\", axis=1)\n",
    "\n",
    "        combined_df['glucose'] = combined_df['glucose'].astype(str).astype(float)\n",
    "        combined_df['basal'] = combined_df['basal'].astype(str).astype(float)\n",
    "        combined_df['bolus'] = combined_df['bolus'].astype(str).astype(float)\n",
    "        combined_df['macc'] = combined_df['macc'].astype(str).astype(float)\n",
    "\n",
    "        # here, basal is filled with the ffill method since the values are constantly infused\n",
    "        combined_df['basal'] = combined_df['basal'].fillna(method = 'ffill')\n",
    "        combined_df['basal'] = combined_df['basal'].fillna(method = 'bfill')\n",
    "        ## erst hier reokace with 0 \n",
    "        # bolus is filled with 0 for nan values since most often missing values means that no bolus was infused\n",
    "        combined_df['bolus'] = combined_df['bolus'].fillna(0)\n",
    "        combined_df = combined_df.set_index('ts')\n",
    "\n",
    "        print('Before Linear')\n",
    "        print(subject_ID, 'intra:', combined_df.isna().sum())\n",
    "\n",
    "        # here, linear interpolation for training data and extrapolation for test data for consecutive 2 hours is applied to fill some of the nan values in glucose\n",
    "        # and exercise data\n",
    "\n",
    "        # if we want to interpolate and extrapolate all missing values modus interpolation is used \n",
    "        if (modus == 'interpolation'):\n",
    "            combined_df = combined_df.interpolate(method = \"linear\", limit_direction=\"both\") #, limit_direction = 'both') \n",
    "            #combined_df2 = combined_df.copy()\n",
    "            #combined_df2['glucose'] = combined_df2['glucose'].interpolate(method=\"slinear\", fill_value=\"extrapolate\", limit_direction=\"both\")\n",
    "            #combined_df2['macc'] = combined_df2['macc'].interpolate(method=\"slinear\", fill_value=\"extrapolate\", limit_direction=\"both\")\n",
    "\n",
    "        # if we want to interpolate onlyup to 2 hours of missing values and then remove biigger gaps the modus gapsremove is used\n",
    "        elif(modus == 'gapsremove'): \n",
    "            combined_df = combined_df.interpolate(method = \"linear\", limit = 48, limit_direction=\"both\") #, limit_direction = 'both') \n",
    "            #combined_df2 = combined_df.copy()\n",
    "            #combined_df2['glucose'] = combined_df2['glucose'].interpolate(method=\"slinear\", limit = 48, fill_value=\"extrapolate\", limit_direction=\"both\")\n",
    "            #combined_df2['macc'] = combined_df2['macc'].interpolate(method=\"slinear\", limit = 48, fill_value=\"extrapolate\", limit_direction=\"both\")\n",
    "            \n",
    "\n",
    "        combined_df = combined_df.reset_index()\n",
    "        #combined_df2 = combined_df2.reset_index()\n",
    "\n",
    "        # then the other exxercise data is filled with -1 for nan values indicating that no data was recorded\n",
    "        # those gaps were not removed, as glucose should be recorded continously to assign the classes, and they have the highest impact for the models\n",
    "        # and missing values could influence the performance significantly\n",
    "        # but it cannot be asserted that the patients will wear the wearable continously, as why the model should learn to ignore -1 values\n",
    "        combined_df['macc'] = combined_df['macc'].fillna(-1)\n",
    "        #combined_df2['macc'] = combined_df2['macc'].fillna(-1)\n",
    "\n",
    "        # create a column called Class and assign the value 0 to keep track of still available instances without a class\n",
    "        # then assing all glucose values below 70 mg/dL the Class 1\n",
    "        combined_df[\"Class\"] = -1\n",
    "        combined_df.loc[combined_df[\"glucose\"] <= 70, \"Class\"] = 0\n",
    "\n",
    "        # create a list containing the timestamps of hypoglycemic events \n",
    "        list_hypo = (combined_df.loc[combined_df[\"Class\"] == 0, \"ts\"]).to_numpy()\n",
    "\n",
    "        # call the function Class_generatiuon with wanted intervalls before a hypoglycemic event in minutes\n",
    "        combined_df = Class_generation(combined_df, 0, 15, 1, list_hypo) # 0-15\n",
    "        combined_df = Class_generation(combined_df, 15, 30, 2, list_hypo)  # 15-30 \n",
    "        combined_df = Class_generation(combined_df, 30, 60, 3, list_hypo)  # 30-60\n",
    "        combined_df = Class_generation(combined_df, 60, 120, 4, list_hypo)  # 1-2 \n",
    "        combined_df = Class_generation(combined_df, 120, 240, 5, list_hypo) # 2-4\n",
    "        combined_df = Class_generation(combined_df, 240, 480, 6, list_hypo)  # 4-8\n",
    "        combined_df = Class_generation(combined_df, 480, 720, 7, list_hypo)  # 8-12\n",
    "        combined_df = Class_generation(combined_df, 720, 1440, 8, list_hypo)  # 12-24\n",
    "        combined_df = Class_generation(combined_df, 1440, 2880, 9, list_hypo)  # 24-48\n",
    "        # 0 could be no hypoglycemia\n",
    "        combined_df.loc[combined_df[\"Class\"] == -1, \"Class\"] = 10\n",
    "\n",
    "        ## same for test data\n",
    "        '''combined_df2[\"Class\"] = -1\n",
    "        combined_df2.loc[combined_df2[\"glucose\"] <= 70, \"Class\"] = 0\n",
    "\n",
    "        # create a list containing the timestamps of hypoglycemic events \n",
    "        list_hypo = (combined_df2.loc[combined_df2[\"Class\"] == 0, \"ts\"]).to_numpy()\n",
    "\n",
    "        # call the function Class_generatiuon with wanted intervalls before a hypoglycemic event in minutes\n",
    "        combined_df2 = Class_generation(combined_df2, 0, 15, 1, list_hypo)  # 0-15\n",
    "        combined_df2 = Class_generation(combined_df2, 15, 30, 2, list_hypo)  # 15-30 \n",
    "        combined_df2 = Class_generation(combined_df2, 30, 60, 3, list_hypo)  # 30-60\n",
    "        combined_df2 = Class_generation(combined_df2, 60, 120, 4, list_hypo)  # 1-2 \n",
    "        combined_df2 = Class_generation(combined_df2, 120, 240, 5, list_hypo) # 2-4\n",
    "        combined_df2 = Class_generation(combined_df2, 240, 480, 6, list_hypo)  # 4-8\n",
    "        combined_df2 = Class_generation(combined_df2, 480, 720, 7, list_hypo)  # 8-12\n",
    "        combined_df2 = Class_generation(combined_df2, 720, 1440, 8, list_hypo)  # 12-24\n",
    "        combined_df2 = Class_generation(combined_df2, 1440, 2880, 9, list_hypo)  # 24-48\n",
    "        # 0 could be no hypoglycemia\n",
    "        combined_df2.loc[combined_df2[\"Class\"] == -1, \"Class\"] = 10'''\n",
    "\n",
    "        # call the function Remove_big_gaps for identifying consecutive nan values which are more than 2 hours \n",
    "        # and create subdataframes for each patient without any gaps, then save them as single csv files\n",
    "        print('After Linear')\n",
    "        #print(subject_ID, 'intra:', combined_df2.isna().sum())\n",
    "        print(subject_ID, 'extra:', combined_df.isna().sum())\n",
    "\n",
    "        \n",
    "        print(np.bincount(combined_df['Class']))\n",
    "        print(len(combined_df['Class']))\n",
    "\n",
    "        #print(np.bincount(combined_df2['Class']))\n",
    "        #print(len(combined_df2['Class']))\n",
    "\n",
    "        if (modus == 'gapsremove'):\n",
    "            Remove_big_gaps(combined_df, subject_ID, version)\n",
    "        elif (modus == 'interpolation'):\n",
    "            file_name = \"NEW_DATA/TRAIN/%s_%i_INTER.csv\" % (subject_ID, version)\n",
    "            #file_name2 = \"NEW_DATA/TEST/%s_%i_EXTRA.csv\" % (subject_ID, version)\n",
    "            combined_df.to_csv(file_name)\n",
    "            #combined_df2.to_csv(file_name2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Linear\n",
      "559 intra: glucose       1663\n",
      "basal            0\n",
      "bolus            0\n",
      "macc           816\n",
      "Subject_ID       0\n",
      "dtype: int64\n",
      "After Linear\n",
      "559 extra: ts            0\n",
      "glucose       0\n",
      "basal         0\n",
      "bolus         0\n",
      "macc          0\n",
      "Subject_ID    0\n",
      "Class         0\n",
      "dtype: int64\n",
      "[ 597  177  162  313  602 1160 2154 1736 3311 2592 2247]\n",
      "15051\n",
      "Before Linear\n",
      "563 intra: glucose       1101\n",
      "basal            0\n",
      "bolus            0\n",
      "macc          1716\n",
      "Subject_ID       0\n",
      "dtype: int64\n",
      "After Linear\n",
      "563 extra: ts            0\n",
      "glucose       0\n",
      "basal         0\n",
      "bolus         0\n",
      "macc          0\n",
      "Subject_ID    0\n",
      "Class         0\n",
      "dtype: int64\n",
      "[ 344  127  121  226  429  710 1339 1217 2822 3829 4716]\n",
      "15880\n",
      "Before Linear\n",
      "570 intra: glucose       768\n",
      "basal           0\n",
      "bolus           0\n",
      "macc          417\n",
      "Subject_ID      0\n",
      "dtype: int64\n",
      "After Linear\n",
      "570 extra: ts            0\n",
      "glucose       0\n",
      "basal         0\n",
      "bolus         0\n",
      "macc          0\n",
      "Subject_ID    0\n",
      "Class         0\n",
      "dtype: int64\n",
      "[ 230   87   78  137  251  420  775  763 2012 2847 6992]\n",
      "14592\n",
      "Before Linear\n",
      "575 intra: glucose       1376\n",
      "basal            0\n",
      "bolus            0\n",
      "macc          1001\n",
      "Subject_ID       0\n",
      "dtype: int64\n",
      "After Linear\n",
      "575 extra: ts            0\n",
      "glucose       0\n",
      "basal         0\n",
      "bolus         0\n",
      "macc          0\n",
      "Subject_ID    0\n",
      "Class         0\n",
      "dtype: int64\n",
      "[1288  288  257  481  921 1646 2749 1919 3370 1976 1012]\n",
      "15907\n",
      "Before Linear\n",
      "588 intra: glucose       558\n",
      "basal           0\n",
      "bolus           0\n",
      "macc          675\n",
      "Subject_ID      0\n",
      "dtype: int64\n",
      "After Linear\n",
      "588 extra: ts            0\n",
      "glucose       0\n",
      "basal         0\n",
      "bolus         0\n",
      "macc          0\n",
      "Subject_ID    0\n",
      "Class         0\n",
      "dtype: int64\n",
      "[ 141   77   69  132  242  458  805  697 1632 2154 9683]\n",
      "16090\n",
      "Before Linear\n",
      "591 intra: glucose       2002\n",
      "basal            0\n",
      "bolus            0\n",
      "macc          1444\n",
      "Subject_ID       0\n",
      "dtype: int64\n",
      "After Linear\n",
      "591 extra: ts            0\n",
      "glucose       0\n",
      "basal         0\n",
      "bolus         0\n",
      "macc          0\n",
      "Subject_ID    0\n",
      "Class         0\n",
      "dtype: int64\n",
      "[ 812  234  213  402  771 1351 2248 1962 3810 2814 1068]\n",
      "15685\n",
      "Before Linear\n",
      "540 intra: glucose       1332\n",
      "basal            0\n",
      "bolus            0\n",
      "macc          8768\n",
      "Subject_ID       0\n",
      "dtype: int64\n",
      "After Linear\n",
      "540 extra: ts            0\n",
      "glucose       0\n",
      "basal         0\n",
      "bolus         0\n",
      "macc          0\n",
      "Subject_ID    0\n",
      "Class         0\n",
      "dtype: int64\n",
      "[1040  314  298  566 1025 1707 2779 1952 3392 2156  946]\n",
      "16175\n",
      "Before Linear\n",
      "544 intra: glucose       2469\n",
      "basal            0\n",
      "bolus            0\n",
      "macc          2045\n",
      "Subject_ID       0\n",
      "dtype: int64\n",
      "After Linear\n",
      "544 extra: ts            0\n",
      "glucose       0\n",
      "basal         0\n",
      "bolus         0\n",
      "macc          0\n",
      "Subject_ID    0\n",
      "Class         0\n",
      "dtype: int64\n",
      "[ 191   84   75  122  216  432  864  864 2409 2792 7759]\n",
      "15808\n",
      "Before Linear\n",
      "552 intra: glucose       3604\n",
      "basal            0\n",
      "bolus            0\n",
      "macc          7795\n",
      "Subject_ID       0\n",
      "dtype: int64\n",
      "After Linear\n",
      "552 extra: ts            0\n",
      "glucose       0\n",
      "basal         0\n",
      "bolus         0\n",
      "macc          0\n",
      "Subject_ID    0\n",
      "Class         0\n",
      "dtype: int64\n",
      "[ 466  142  137  261  514 1007 1760 1354 2814 2925 3668]\n",
      "15048\n",
      "Before Linear\n",
      "567 intra: glucose       3159\n",
      "basal            0\n",
      "bolus            0\n",
      "macc          6515\n",
      "Subject_ID       0\n",
      "dtype: int64\n",
      "After Linear\n",
      "567 extra: ts            0\n",
      "glucose       0\n",
      "basal         0\n",
      "bolus         0\n",
      "macc          0\n",
      "Subject_ID    0\n",
      "Class         0\n",
      "dtype: int64\n",
      "[ 943  140  125  238  453  878 1720 1495 3638 4785 1991]\n",
      "16406\n",
      "Before Linear\n",
      "584 intra: glucose       1428\n",
      "basal            0\n",
      "bolus            0\n",
      "macc          4273\n",
      "Subject_ID       0\n",
      "dtype: int64\n",
      "After Linear\n",
      "584 extra: ts            12\n",
      "glucose        0\n",
      "basal          0\n",
      "bolus          0\n",
      "macc           0\n",
      "Subject_ID     0\n",
      "Class          0\n",
      "dtype: int64\n",
      "[  144    72    64   126   236   404   589   528  1439  1783 10869]\n",
      "16254\n",
      "Before Linear\n",
      "596 intra: glucose       3012\n",
      "basal            0\n",
      "bolus            0\n",
      "macc          7715\n",
      "Subject_ID       0\n",
      "dtype: int64\n",
      "After Linear\n",
      "596 extra: ts            0\n",
      "glucose       0\n",
      "basal         0\n",
      "bolus         0\n",
      "macc          0\n",
      "Subject_ID    0\n",
      "Class         0\n",
      "dtype: int64\n",
      "[ 316  161  143  260  516  990 1768 1598 3501 3992 3387]\n",
      "16632\n"
     ]
    }
   ],
   "source": [
    "# main function containing the files with their corresponsing subject id, modus and version \n",
    "# this function is highly influenced by the code of https://github.com/r-cui/GluPred/blob/master/preprocess/linker.py\n",
    "def main():\n",
    "    versions_arr = [2018, 2020]\n",
    "\n",
    "    for v in versions_arr:\n",
    "        if (v == 2018):\n",
    "            ## first preprocess the training and test data of the cohort of 2018\n",
    "            patient_index = [559, 563, 570, 575, 588, 591]\n",
    "            train_files = ['/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2018/train/559-ws-training.xml', \n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2018/train/563-ws-training.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2018/train/570-ws-training.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2018/train/575-ws-training.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2018/train/588-ws-training.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2018/train/591-ws-training.xml'\n",
    "                        ]\n",
    "\n",
    "\n",
    "            test_files = ['/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2018/test/559-ws-testing.xml', \n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2018/test/563-ws-testing.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2018/test/570-ws-testing.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2018/test/575-ws-testing.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2018/test/588-ws-testing.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2018/test/591-ws-testing.xml'\n",
    "                        ]\n",
    "            \n",
    "        elif (v == 2020):\n",
    "            patient_index = [540, 544, 552, 567, 584, 596]\n",
    "            train_files = ['/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2020/train/540-ws-training.xml', \n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2020/train/544-ws-training.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2020/train/552-ws-training.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2020/train/567-ws-training.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2020/train/584-ws-training.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2020/train/596-ws-training.xml'\n",
    "                        ]\n",
    "\n",
    "\n",
    "            test_files = ['/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2020/test/540-ws-testing.xml', \n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2020/test/544-ws-testing.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2020/test/552-ws-testing.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2020/test/567-ws-testing.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2020/test/584-ws-testing.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2020/test/596-ws-testing.xml'\n",
    "                        ]\n",
    "\n",
    "                \n",
    "        load_data(train_files, test_files, patient_index, version=v, modus= 'interpolation') #'gapsremove'\n",
    "        \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Linear\n",
      "559 intra: glucose       1663\n",
      "basal            0\n",
      "bolus            0\n",
      "macc           816\n",
      "Subject_ID       0\n",
      "dtype: int64\n",
      "After Linear\n",
      "559 extra: ts              0\n",
      "glucose       113\n",
      "basal           0\n",
      "bolus           0\n",
      "macc            0\n",
      "Subject_ID      0\n",
      "Class           0\n",
      "dtype: int64\n",
      "[ 597  177  162  313  602 1160 2154 1736 3311 2592 2247]\n",
      "15051\n",
      "Before Linear\n",
      "563 intra: glucose       1101\n",
      "basal            0\n",
      "bolus            0\n",
      "macc          1716\n",
      "Subject_ID       0\n",
      "dtype: int64\n",
      "After Linear\n",
      "563 extra: ts              0\n",
      "glucose       356\n",
      "basal           0\n",
      "bolus           0\n",
      "macc            0\n",
      "Subject_ID      0\n",
      "Class           0\n",
      "dtype: int64\n",
      "[ 344  127  121  226  429  710 1339 1217 2822 3829 4716]\n",
      "15880\n",
      "Before Linear\n",
      "570 intra: glucose       768\n",
      "basal           0\n",
      "bolus           0\n",
      "macc          417\n",
      "Subject_ID      0\n",
      "dtype: int64\n",
      "After Linear\n",
      "570 extra: ts             0\n",
      "glucose       50\n",
      "basal          0\n",
      "bolus          0\n",
      "macc           0\n",
      "Subject_ID     0\n",
      "Class          0\n",
      "dtype: int64\n",
      "[ 230   87   78  137  251  420  775  763 2012 2847 6992]\n",
      "14592\n",
      "Before Linear\n",
      "575 intra: glucose       1376\n",
      "basal            0\n",
      "bolus            0\n",
      "macc          1001\n",
      "Subject_ID       0\n",
      "dtype: int64\n",
      "After Linear\n",
      "575 extra: ts             0\n",
      "glucose       61\n",
      "basal          0\n",
      "bolus          0\n",
      "macc           0\n",
      "Subject_ID     0\n",
      "Class          0\n",
      "dtype: int64\n",
      "[1288  288  257  481  921 1646 2749 1919 3370 1976 1012]\n",
      "15907\n",
      "Before Linear\n",
      "588 intra: glucose       558\n",
      "basal           0\n",
      "bolus           0\n",
      "macc          675\n",
      "Subject_ID      0\n",
      "dtype: int64\n",
      "After Linear\n",
      "588 extra: ts             0\n",
      "glucose       58\n",
      "basal          0\n",
      "bolus          0\n",
      "macc           0\n",
      "Subject_ID     0\n",
      "Class          0\n",
      "dtype: int64\n",
      "[ 141   77   69  132  242  458  805  697 1632 2154 9683]\n",
      "16090\n",
      "Before Linear\n",
      "591 intra: glucose       2002\n",
      "basal            0\n",
      "bolus            0\n",
      "macc          1444\n",
      "Subject_ID       0\n",
      "dtype: int64\n",
      "After Linear\n",
      "591 extra: ts               0\n",
      "glucose       1120\n",
      "basal            0\n",
      "bolus            0\n",
      "macc             0\n",
      "Subject_ID       0\n",
      "Class            0\n",
      "dtype: int64\n",
      "[ 690  234  213  402  771 1351 2248 1962 3810 2814 1190]\n",
      "15685\n",
      "Before Linear\n",
      "540 intra: glucose       1332\n",
      "basal            0\n",
      "bolus            0\n",
      "macc          8768\n",
      "Subject_ID       0\n",
      "dtype: int64\n",
      "After Linear\n",
      "540 extra: ts              0\n",
      "glucose       303\n",
      "basal           0\n",
      "bolus           0\n",
      "macc            0\n",
      "Subject_ID      0\n",
      "Class           0\n",
      "dtype: int64\n",
      "[1040  314  298  566 1025 1707 2779 1952 3392 2156  946]\n",
      "16175\n",
      "Before Linear\n",
      "544 intra: glucose       2469\n",
      "basal            0\n",
      "bolus            0\n",
      "macc          2045\n",
      "Subject_ID       0\n",
      "dtype: int64\n",
      "After Linear\n",
      "544 extra: ts               0\n",
      "glucose       1398\n",
      "basal            0\n",
      "bolus            0\n",
      "macc             0\n",
      "Subject_ID       0\n",
      "Class            0\n",
      "dtype: int64\n",
      "[ 191   84   75  122  216  432  864  864 2409 2792 7759]\n",
      "15808\n",
      "Before Linear\n",
      "552 intra: glucose       3604\n",
      "basal            0\n",
      "bolus            0\n",
      "macc          7795\n",
      "Subject_ID       0\n",
      "dtype: int64\n",
      "After Linear\n",
      "552 extra: ts               0\n",
      "glucose       2294\n",
      "basal            0\n",
      "bolus            0\n",
      "macc             0\n",
      "Subject_ID       0\n",
      "Class            0\n",
      "dtype: int64\n",
      "[ 466  142  137  261  514 1007 1760 1354 2814 2925 3668]\n",
      "15048\n",
      "Before Linear\n",
      "567 intra: glucose       3159\n",
      "basal            0\n",
      "bolus            0\n",
      "macc          6515\n",
      "Subject_ID       0\n",
      "dtype: int64\n",
      "After Linear\n",
      "567 extra: ts              0\n",
      "glucose       982\n",
      "basal           0\n",
      "bolus           0\n",
      "macc            0\n",
      "Subject_ID      0\n",
      "Class           0\n",
      "dtype: int64\n",
      "[ 943  140  125  238  453  878 1720 1495 3638 4785 1991]\n",
      "16406\n",
      "Before Linear\n",
      "584 intra: glucose       1428\n",
      "basal            0\n",
      "bolus            0\n",
      "macc          4273\n",
      "Subject_ID       0\n",
      "dtype: int64\n",
      "After Linear\n",
      "584 extra: ts             12\n",
      "glucose       219\n",
      "basal           0\n",
      "bolus           0\n",
      "macc            0\n",
      "Subject_ID      0\n",
      "Class           0\n",
      "dtype: int64\n",
      "[  144    72    64   126   236   404   589   528  1439  1783 10869]\n",
      "16254\n",
      "Before Linear\n",
      "596 intra: glucose       3012\n",
      "basal            0\n",
      "bolus            0\n",
      "macc          7715\n",
      "Subject_ID       0\n",
      "dtype: int64\n",
      "After Linear\n",
      "596 extra: ts               0\n",
      "glucose       1660\n",
      "basal            0\n",
      "bolus            0\n",
      "macc             0\n",
      "Subject_ID       0\n",
      "Class            0\n",
      "dtype: int64\n",
      "[ 316  161  143  260  516  990 1768 1598 3501 3992 3387]\n",
      "16632\n"
     ]
    }
   ],
   "source": [
    "# main function containing the files with their corresponsing subject id, modus and version \n",
    "# this function is highly influenced by the code of https://github.com/r-cui/GluPred/blob/master/preprocess/linker.py\n",
    "def main():\n",
    "    versions_arr = [2018, 2020]\n",
    "\n",
    "    for v in versions_arr:\n",
    "        if (v == 2018):\n",
    "            ## first preprocess the training and test data of the cohort of 2018\n",
    "            patient_index = [559, 563, 570, 575, 588, 591]\n",
    "            train_files = ['/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2018/train/559-ws-training.xml', \n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2018/train/563-ws-training.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2018/train/570-ws-training.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2018/train/575-ws-training.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2018/train/588-ws-training.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2018/train/591-ws-training.xml'\n",
    "                        ]\n",
    "\n",
    "\n",
    "            test_files = ['/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2018/test/559-ws-testing.xml', \n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2018/test/563-ws-testing.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2018/test/570-ws-testing.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2018/test/575-ws-testing.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2018/test/588-ws-testing.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2018/test/591-ws-testing.xml'\n",
    "                        ]\n",
    "            \n",
    "        elif (v == 2020):\n",
    "            patient_index = [540, 544, 552, 567, 584, 596]\n",
    "            train_files = ['/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2020/train/540-ws-training.xml', \n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2020/train/544-ws-training.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2020/train/552-ws-training.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2020/train/567-ws-training.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2020/train/584-ws-training.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2020/train/596-ws-training.xml'\n",
    "                        ]\n",
    "\n",
    "\n",
    "            test_files = ['/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2020/test/540-ws-testing.xml', \n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2020/test/544-ws-testing.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2020/test/552-ws-testing.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2020/test/567-ws-testing.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2020/test/584-ws-testing.xml',\n",
    "                        '/Users/beyzacinar/Desktop/MA/CODE/OhioT1DM/2020/test/596-ws-testing.xml'\n",
    "                        ]\n",
    "\n",
    "                \n",
    "        load_data(train_files, test_files, patient_index, version=v, modus= 'gapsremove') \n",
    "        \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
